{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e48ec5a1-95e1-4660-8564-d67a26083b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import ast\n",
    "\n",
    "import sqlparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine, MetaData, Table, literal_column, Column\n",
    "from sqlalchemy.sql import select, func, or_\n",
    "from sqlalchemy.dialects.mysql import insert\n",
    "from sqlalchemy.dialects.mysql.types import VARCHAR, TINYINT, TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6108b0c-aaa3-4e27-9604-ce40e6686d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4a77584-1141-406f-a066-2f188615fcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = MetaData()\n",
    "metadata.reflect(engine, schema=\"weaselbot\")\n",
    "# Table(\"regions\", metadata, autoload_with=engine, schema=\"paxminer\")\n",
    "\n",
    "Table(\"regions\", \n",
    "      metadata, \n",
    "      Column(\"region\", VARCHAR(length=45), nullable=False, primary_key=True), \n",
    "      Column(\"slack_token\", VARCHAR(length=90), nullable=False),\n",
    "      Column(\"schema_name\", VARCHAR(length=45), nullable=True, default=None),\n",
    "      Column(\"active\", TINYINT(), default=1),\n",
    "      Column(\"firstf_channel\", VARCHAR(length=45), nullable=True, default=None),\n",
    "      Column(\"contact\", VARCHAR(length=45), nullable=True, default=None),\n",
    "      Column(\"send_pax_charts\", TINYINT(), default=0),\n",
    "      Column(\"send_ao_leaderboard\", TINYINT(), default=0),\n",
    "      Column(\"send_q_charts\", TINYINT(), default=0),\n",
    "      Column(\"send_region_leaderboard\", TINYINT(), default=0),\n",
    "      Column(\"send_region_uniquepax_chart\", TINYINT(), default=0),\n",
    "      Column(\"send_region_stats\", VARCHAR(length=45), default=0),\n",
    "      Column(\"send_mid_month_charts\", VARCHAR(length=45), default=0),\n",
    "      Column(\"comments\", TEXT()),\n",
    "      schema=\"paxminer\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c093b425-e314-4f73-bdd1-84c8353b8ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = metadata.tables[\"weaselbot.combined_regions\"]\n",
    "cu = metadata.tables[\"weaselbot.combined_users\"]\n",
    "cud = metadata.tables[\"weaselbot.combined_users_dup\"]\n",
    "ca = metadata.tables[\"weaselbot.combined_aos\"]\n",
    "cb = metadata.tables[\"weaselbot.combined_beatdowns\"]\n",
    "catt = metadata.tables[\"weaselbot.combined_attendance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9abd02ac-4cb5-4186-a201-575dcdce6f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_statement(table, insert_values, update_cols):\n",
    "    sql = insert(table).values(insert_values)\n",
    "    on_dup = sql.on_duplicate_key_update(\n",
    "        {v.name: v for v in sql.inserted if v.name in update_cols}\n",
    "    )\n",
    "    return on_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a85bd8b3-b7e5-4b4f-99c6-abc8ff64011a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_subquery(metadata):\n",
    "    cb = metadata.tables[\"weaselbot.combined_beatdowns\"]\n",
    "    a = metadata.tables[\"weaselbot.combined_aos\"]\n",
    "\n",
    "    sql = select(\n",
    "        a.c.region_id,\n",
    "        func.max(cb.c.timestamp).label(\"max_timestamp\"),\n",
    "        func.max(cb.c.ts_edited).label(\"max_ts_edited\"),\n",
    "        func.count().label(\"beatdown_count\"),\n",
    "    )\n",
    "    sql = sql.select_from(cb.join(a, cb.c.ao_id == a.c.ao_id))\n",
    "    sql = sql.group_by(a.c.region_id).subquery(\"b\")\n",
    "    return sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90eaa192-73df-4a09-9a4c-d20cfe6b7911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paxminer_region_query(metadata):\n",
    "    r = metadata.tables[\"paxminer.regions\"]\n",
    "    cr = metadata.tables[\"weaselbot.combined_regions\"]\n",
    "    sub = region_subquery(metadata)\n",
    "\n",
    "    sql = select(\n",
    "        r.c.schema_name,\n",
    "        r.c.region.label(\"region_name\"),\n",
    "        sub.c.max_timestamp,\n",
    "        sub.c.max_ts_edited,\n",
    "        sub.c.beatdown_count,\n",
    "        cr.c.region_id,\n",
    "    )\n",
    "    sql = sql.select_from(\n",
    "        r.outerjoin(cr, r.c.schema_name == cr.c.schema_name).outerjoin(sub, cr.c.region_id == sub.c.region_id)\n",
    "    )\n",
    "\n",
    "    return sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ba1d187-0cc6-4312-88bc-c0c55ab4d937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weaselbot_region_query(metadata):\n",
    "    cr = metadata.tables[\"weaselbot.combined_regions\"]\n",
    "    sub = region_subquery(metadata)\n",
    "\n",
    "    sql = select(cr, sub.c.beatdown_count)\n",
    "    sql = sql.select_from(cr.outerjoin(sub, cr.c.region_id == sub.c.region_id))\n",
    "\n",
    "    return sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7de42a6-6bea-4e12-b966-d2a7c84b91f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "paxminer_region_sql = paxminer_region_query(metadata) # verified\n",
    "weaselbot_region_sql = weaselbot_region_query(metadata) # verified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55c0bf51-d32c-4ad6-8989-8f27935f8339",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sample data to move forward with ###\n",
    "\n",
    "region_data = dict(schema_name=\"f3alamo f3chicago f3naperville f3omaha f3stcharles\".split(),\n",
    "                   region_name=\"Alamo Chicago Naperville Omaha St_Charles\".split(),\n",
    "                   max_timestamp=[1704824582.100129, 1704808955.413849, None, 1697642801.087519, 1704825215.550419],\n",
    "                   max_ts_edited=[1704824731, 1704724809, None, None, 1704825356]\n",
    "                  )\n",
    "df_regions = pd.DataFrame(region_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "233608b2-a4fc-499d-a05d-a3d2c67a8a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_values = df_regions.to_dict(\"records\")\n",
    "update_cols = (\"region_name\", \"max_timestamp\", \"max_ts_edited\")\n",
    "region_insert_sql = insert_statement(cr, insert_values, update_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36db3ac-6162-43a8-b5b2-c89e57050e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sqlparse.format(region_insert_sql.compile(engine, compile_kwargs={\"literal_binds\": True}).__str__(), keyword_case=\"upper\", reindent=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5215e12-2ce7-4808-a6ed-2e2ac94f23a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = dict(\n",
    "    region_id=pd.StringDtype(),  # this is a string everywhere else\n",
    "    region_name=pd.StringDtype(),\n",
    "    schema_name=pd.StringDtype(),\n",
    "    slack_team_id=pd.StringDtype(),\n",
    "    max_timestamp=pd.Float64Dtype(),\n",
    "    max_ts_edited=pd.Float64Dtype(),\n",
    "    beatdown_count=pd.Int16Dtype()\n",
    ")\n",
    "\n",
    "with engine.begin() as cnxn:\n",
    "    df_regions = pd.read_sql(weaselbot_region_sql, cnxn, dtype=dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63b4bf40-86e6-4341-b227-80fe159ae900",
   "metadata": {},
   "outputs": [],
   "source": [
    "from f3_data_builder import pull_main_data, build_users, build_aos, build_beatdowns, build_attendance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b648973a-fc78-4451-ba58-a478d4e5d020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting f3alamo... Done\n",
      "starting f3albany... Done\n",
      "starting f3albuquerque... Done\n",
      "starting f3alliance... Done\n",
      "starting f3anderson... Done\n",
      "starting f3annapolis... Done\n",
      "starting f3atlanta... Done\n",
      "starting f3austin... Done\n",
      "starting f3badlands... Done\n",
      "starting f3beast... Done\n",
      "starting f3bellingham... Done\n",
      "starting f3blueridge... Done\n",
      "starting f3borderlands... Done\n",
      "starting f3brentwood... Done\n",
      "starting f3bruco... Done\n",
      "starting f3youngsville... Done\n",
      "starting f3carpex... Done\n",
      "starting f3centralarkansas... Done\n",
      "starting f3central_il... Done\n",
      "starting f3charleston... Done\n",
      "starting f3charlottesville... Done\n",
      "starting f3cherokee... Done\n",
      "starting f3cheyenne... Done\n",
      "starting f3chicago... Done\n",
      "starting f3churham... Done\n",
      "starting f3clearwater... Done\n",
      "starting f3cleburne... Done\n",
      "starting f3cleveland... Done\n",
      "starting f3coloradosprings... Done\n",
      "starting f3columbia... Done\n",
      "starting f3columbus... Done\n",
      "starting f3dallas... Done\n",
      "starting f3davidson... Done\n",
      "starting f3dayton... Done\n",
      "starting f3delhi_ncr... Done\n",
      "starting f3delmar... Done\n",
      "starting f3denver... Done\n",
      "starting f3desmoines... Done\n",
      "starting f3devcommunity... Done\n",
      "starting f3durango... Done\n",
      "starting f3enc... Done\n",
      "starting f3evansville... Done\n",
      "starting f3expedition... Done\n",
      "starting f3fargo... Done\n",
      "starting fia_naperville... \n",
      "(mysql.connector.errors.ProgrammingError) 1142 (42000): SHOW command denied to user 'f3chicago'@'136.30.89.84' for table 'users'\n",
      "[SQL: SHOW CREATE TABLE `fia_naperville`.`users`]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
      "Done\n",
      "starting fia_omaha... \n",
      "(mysql.connector.errors.ProgrammingError) 1142 (42000): SHOW command denied to user 'f3chicago'@'136.30.89.84' for table 'users'\n",
      "[SQL: SHOW CREATE TABLE `fia_omaha`.`users`]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
      "Done\n",
      "starting fia_sanford... \n",
      "(mysql.connector.errors.ProgrammingError) 1142 (42000): SHOW command denied to user 'f3chicago'@'136.30.89.84' for table 'users'\n",
      "[SQL: SHOW CREATE TABLE `fia_sanford`.`users`]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
      "Done\n",
      "starting f3florence... Done\n",
      "starting f3flomo... Done\n",
      "starting f3foothills... Done\n",
      "starting f3forsyth... Done\n",
      "starting f3fortcollins... Done\n",
      "starting f3fortworth... Done\n",
      "starting f3franklin... Done\n",
      "starting f3geneva... Done\n",
      "starting f3glacier... Done\n",
      "starting f3gwinnett... Done\n",
      "starting f3hillcountry... Done\n",
      "starting f3houston... Done\n",
      "starting f3hr... Done\n",
      "starting f3huntsville... Done\n",
      "starting f3indianapolis... Done\n",
      "starting f3indianvalley... Done\n",
      "starting f3jackson... Done\n",
      "starting f3jacksontn... Done\n",
      "starting f3jax... Done\n",
      "starting f3jeffco... Done\n",
      "starting f3katy... Done\n",
      "starting f3kc... Done\n",
      "starting f3kcmo... Done\n",
      "starting f3kingsden... Done\n",
      "starting f3kinston... Done\n",
      "starting f3knoxville... Done\n",
      "starting f3lakewylie... Done\n",
      "starting f3lexington... Done\n",
      "starting f3louisville... Done\n",
      "starting f3lubbock... Done\n",
      "starting f3macon... Done\n",
      "starting f3marshall... Done\n",
      "starting f3meca... Done\n",
      "starting f3memphis... Done\n",
      "starting f3minthill... Done\n",
      "starting f3monterey... Done\n",
      "starting f3morris... Done\n",
      "starting f3muletown... Done\n",
      "starting f3murfreesboro... Done\n",
      "starting f3naperville... Done\n",
      "starting f3nashville... Done\n",
      "starting f3newbern... Done\n",
      "starting f3ne_wake... Done\n",
      "starting f3noga... Done\n",
      "starting f3noho... Done\n",
      "starting f3nola... Done\n",
      "starting f3nolensville... Done\n",
      "starting f3northlake... Done\n",
      "starting f3nwarkansas... Done\n",
      "starting f3nwhighway... Done\n",
      "starting f3northsandiego... Done\n",
      "starting f3ocoee... Done\n",
      "starting f3omaha... Done\n",
      "starting f3orlando... Done\n",
      "starting f3parkercounty... Done\n",
      "starting f3pensacola... Done\n",
      "starting f3phoenix... Done\n",
      "starting f3pittsburgh... Done\n",
      "starting f3crossroads... Done\n",
      "starting f3portland... Done\n",
      "starting f3princeton... Done\n",
      "starting f3pugetsound... Done\n",
      "starting f3racecity... Done\n",
      "starting f3raleigh... Done\n",
      "starting f3rapidcity... Done\n",
      "starting f3roanoke... Done\n",
      "starting f3rockhill... Done\n",
      "starting f3roco... Done\n",
      "starting f3slc... Done\n",
      "starting f3sandhills... Done\n",
      "starting f3sclt... Done\n",
      "starting f3shoals... Done\n",
      "starting f3smokies... Done\n",
      "starting f3soco... Done\n",
      "starting f3soil... Done\n",
      "starting f3southcary... Done\n",
      "starting f3southsound... Done\n",
      "starting f3sowmo... Done\n",
      "starting f3spiritofstl... Done\n",
      "starting f3springhill... Done\n",
      "starting f3stl... Done\n",
      "starting f3stlcity... Done\n",
      "starting f3stlmeramec... Done\n",
      "starting f3stcharles... Done\n",
      "starting f3stpete... Done\n",
      "starting f3stsimons... Done\n",
      "starting f3suncoast... Done\n",
      "starting f3ttown... \n",
      "could not convert string to float: '': Error while type casting for column 'timestamp'\n",
      "Done\n",
      "starting f3tallahassee... Done\n",
      "starting f3tampa... Done\n",
      "starting f3techtown... Done\n",
      "starting f3thailand... Done\n",
      "starting f3thecapital... Done\n",
      "starting f3thechuck... Done\n",
      "starting f3thefort... Done\n",
      "starting f3thejunction... Done\n",
      "starting f3thespark... Done\n",
      "starting f3theunion... Done\n",
      "starting f3tornadoalley... Done\n",
      "starting f3tuscon... Done\n",
      "starting f3twincities... Done\n",
      "starting f3waco... Done\n",
      "starting f3washmo... Done\n",
      "starting f3waxahachie... Done\n",
      "starting f3waxhaw... Done\n",
      "starting f3westcobb... Done\n",
      "starting f3westhouston... Done\n",
      "starting f3westindy... Done\n",
      "starting f3westshore... Done\n",
      "starting f3wheaton... Done\n",
      "starting f3wichita... Done\n",
      "starting f3wilson... Done\n",
      "starting f3dc... \n",
      "(mysql.connector.errors.ProgrammingError) 1049 (42000): Unknown database 'f3dc'\n",
      "[SQL: SHOW CREATE TABLE `f3dc`.`users`]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
      "Done\n",
      "starting f3mobile... Done\n",
      "starting f3snacktown... Done\n",
      "starting f3se_michigan... Done\n",
      "starting f3nyon... Done\n",
      "starting f3lowcountry... Done\n",
      "starting fia_temecula... \n",
      "(mysql.connector.errors.ProgrammingError) 1142 (42000): SHOW command denied to user 'f3chicago'@'136.30.89.84' for table 'users'\n",
      "[SQL: SHOW CREATE TABLE `fia_temecula`.`users`]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
      "Done\n",
      "starting f3temecula... Done\n",
      "starting f3thomasville... Done\n"
     ]
    }
   ],
   "source": [
    "df_users_dup, df_aos, df_beatdowns, df_attendance = pull_main_data(df_regions, engine, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bdd6a04-8992-4c9a-a2d5-7e5bc52b9e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beatdowns to process: 75937\n"
     ]
    }
   ],
   "source": [
    "print(f\"beatdowns to process: {len(df_beatdowns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0e322cf-aba0-4992-80ca-9b5e2d369f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building users...\n"
     ]
    }
   ],
   "source": [
    "df_users_dup = build_users(df_users_dup, df_attendance, engine, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "975b07ff-fc87-491a-8f93-a9bb77a8e839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building aos...\n"
     ]
    }
   ],
   "source": [
    "df_aos = build_aos(df_aos, engine, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e64da7e4-22e7-44d0-9cc5-15cd22a5b950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building beatdowns...\n"
     ]
    }
   ],
   "source": [
    "df_beatdowns = build_beatdowns(df_beatdowns, df_users_dup, df_aos, engine, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fb9d3a8-a0e2-4fca-a86f-9790bb933050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building attendance...\n"
     ]
    }
   ],
   "source": [
    "build_attendance(df_attendance, df_users_dup, df_aos, df_beatdowns, engine, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa13d2e-8b83-49e4-891f-c5e2b46f3b44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2263b3-264a-45c5-a622-51d752b5892c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995b8ba2-d7fb-495e-8a64-4959d47da31e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9036e4da-b14b-4e58-aa04-fb9944503544",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e332b58-c27c-4cb3-9a38-2a1dfb152d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630e6a58-6651-4344-8a47-620c4af09147",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PULLING USER TABLE DATA. TEST LOGIC ON JUST ONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f12b990-f10a-4189-9724-c6eeffb40956",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_dup_list, df_aos_list, df_beatdowns_list, df_attendance_list = [], [], [], []\n",
    "users_dtypes = dict(\n",
    "    slack_user_id=pd.StringDtype(),\n",
    "    user_name=pd.StringDtype(),\n",
    "    email=pd.StringDtype(),\n",
    "    region_id=pd.StringDtype()\n",
    ")\n",
    "ao_dtypes = dict(\n",
    "    slack_channel_id=pd.StringDtype(),\n",
    "    ao_name=pd.StringDtype(),\n",
    "    region_id=pd.StringDtype()\n",
    ")\n",
    "beatdown_dtypes = dict(\n",
    "    slack_channel_id=pd.StringDtype(),\n",
    "    slack_q_user_id=pd.StringDtype(),\n",
    "    slack_coq_user_id=pd.StringDtype(),\n",
    "    pax_count=pd.Int16Dtype(),\n",
    "    fng_count=pd.Int16Dtype(),\n",
    "    region_id=pd.StringDtype(),\n",
    "    timestamp=pd.Float64Dtype(),\n",
    "    ts_edited=pd.StringDtype(), # string for now. Then replace \"NA\" string and cast as float\n",
    "    backblast=pd.StringDtype(),\n",
    "    json=pd.StringDtype()\n",
    ")\n",
    "attendance_dtypes = dict(\n",
    "    slack_channel_id=pd.StringDtype(),\n",
    "    slack_q_user_id=pd.StringDtype(),\n",
    "    slack_user_id=pd.StringDtype(),\n",
    "    region_id=pd.StringDtype(),\n",
    "    json=pd.StringDtype()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee789a1a-0748-42dc-a91d-b23a1e057b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in df_regions.itertuples(index=False):\n",
    "    if row.schema_name == \"f3chicago\":\n",
    "        db = row.schema_name\n",
    "        usr = Table(\"users\", metadata, autoload_with=engine, schema=db)\n",
    "        beatdowns = Table(\"beatdowns\", metadata, autoload_with=engine, schema=db)\n",
    "        attendance = Table(\"bd_attendance\", metadata, autoload_with=engine, schema=db)\n",
    "        ao = Table(\"aos\", metadata, autoload_with=engine, schema=db)\n",
    "        \n",
    "        user_sql = select(\n",
    "            usr.c.user_id.label(\"slack_user_id\"),\n",
    "            usr.c.user_name,\n",
    "            usr.c.email,\n",
    "            literal_column(f\"'{row.region_id}'\").label(\"region_id\"),\n",
    "        )\n",
    "        \n",
    "        aos_sql = select(\n",
    "            ao.c.channel_id.label(\"slack_channel_id\"),\n",
    "            ao.c.ao.label(\"ao_name\"),\n",
    "            literal_column(f\"'{row.region_id}'\").label(\"region_id\"),\n",
    "        )\n",
    "        \n",
    "        beatdowns_base_sql = select(beatdowns.c.ao_id.label(\"slack_channel_id\"),\n",
    "                               beatdowns.c.bd_date,\n",
    "                               beatdowns.c.q_user_id.label(\"slack_q_user_id\"),\n",
    "                               beatdowns.c.coq_user_id.label(\"slack_coq_user_id\"),\n",
    "                               beatdowns.c.pax_count,\n",
    "                               beatdowns.c.fng_count,\n",
    "                               literal_column(f\"'{row.region_id}'\").label(\"region_id\"),\n",
    "                               beatdowns.c.timestamp,\n",
    "                               beatdowns.c.ts_edited,\n",
    "                               beatdowns.c.backblast,\n",
    "                               beatdowns.c.json)\n",
    "        beatdowns_sql = beatdowns_base_sql.where(or_(beatdowns.c.timestamp > str(row.max_timestamp),\n",
    "                                                beatdowns.c.ts_edited > str(row.max_ts_edited)))\n",
    "        \n",
    "        attendance_base_sql = select(attendance.c.ao_id.label(\"slack_channel_id\"),\n",
    "                                 attendance.c.date.label(\"bd_date\"),\n",
    "                                 attendance.c.q_user_id.label(\"slack_q_user_id\"),\n",
    "                                 attendance.c.user_id.label(\"slack_user_id\"),\n",
    "                                 literal_column(f\"'{row.region_id}'\").label(\"region_id\"),\n",
    "                                 attendance.c.json)\n",
    "        attendance_sql = attendance_base_sql.where(or_(attendance.c.timestamp > str(row.max_timestamp),\n",
    "                                                attendance.c.ts_edited > str(row.max_ts_edited)))\n",
    "        \n",
    "        beatdowns_no_ts_sql = beatdowns_base_sql\n",
    "        attendance_no_ts_sql = attendance_base_sql\n",
    "        beatdowns_no_ed_sql = beatdowns_base_sql.where(beatdowns.c.timestamp > str(row.max_timestamp))\n",
    "        attendance_no_ed_sql = attendance_base_sql.where(attendance.c.timestamp > str(row.max_timestamp))\n",
    "\n",
    "        with engine.begin() as cnxn:\n",
    "            df_users_dup_list.append(pd.read_sql(user_sql, cnxn, dtype=users_dtypes))\n",
    "            df_aos_list.append(pd.read_sql(aos_sql, cnxn, dtype=ao_dtypes))\n",
    "            if (not math.isnan(row.max_timestamp)) and (not math.isnan(row.max_ts_edited)):\n",
    "                df_beatdowns_list.append(pd.read_sql(beatdowns_sql, cnxn, parse_dates=\"bd_date\", dtype=beatdown_dtypes))\n",
    "                df_attendance_list.append(pd.read_sql(attendance_sql, cnxn, parse_dates=\"bd_date\", dtype=attendance_dtypes))\n",
    "            elif not math.isnan(row.max_timestamp):\n",
    "                df_beatdowns_list.append(pd.read_sql(beatdowns_no_ed_sql, cnxn, parse_dates=\"bd_date\", dtype=beatdown_dtypes))\n",
    "                df_attendance_list.append(pd.read_sql(attendance_no_ed_sql, cnxn, parse_dates=\"bd_date\", dtype=attendance_dtypes))\n",
    "            elif row.beatdown_count == 0:\n",
    "                df_beatdowns_list.append(pd.read_sql(beatdowns_no_ts_sql, cnxn, parse_dates=\"bd_date\", dtype=beatdown_dtypes))\n",
    "                df_attendance_list.append(pd.read_sql(attendance_no_ts_sql, cnxn, parse_dates=\"bd_date\", dtype=attendance_dtypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3c141f-0a1c-4a1f-82f2-d1a857956f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sqlparse.format(beatdowns_no_ed_sql.compile(engine, compile_kwargs={'literal_binds': True}).__str__(), keyword_case='upper', reindent=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a562c7-a6ab-4efe-98c1-e42f30053287",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_dup = pd.concat(df_users_dup_list)\n",
    "df_aos = pd.concat(df_aos_list)\n",
    "df_beatdowns = pd.concat(df_beatdowns_list)\n",
    "df_attendance = pd.concat(df_attendance_list)\n",
    "\n",
    "df_beatdowns.ts_edited = df_beatdowns.ts_edited.replace(\"NA\", pd.NA).astype(pd.Float64Dtype())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ffd21d-16b0-4ea5-a520-efc07631aa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_beatdowns # ts_edited has None and \"NA\" values. json has None and {}. Not good\n",
    "# df_attendance_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1e8961-87b5-4f79-80cb-720dce366141",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_dup[\"email\"] = df_users_dup[\"email\"].str.lower()\n",
    "df_users_dup = df_users_dup[df_users_dup[\"email\"].notna()]\n",
    "\n",
    "df_user_agg = (\n",
    "    df_attendance.groupby([\"slack_user_id\"], as_index=False)[\"bd_date\"].count().rename({\"bd_date\": \"count\"}, axis=1)\n",
    ")\n",
    "df_users = (\n",
    "    df_users_dup.merge(df_user_agg[[\"slack_user_id\", \"count\"]], on=\"slack_user_id\", how=\"left\")\n",
    "    .fillna(0)\n",
    "    .sort_values(by=\"count\", ascending=False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd224cc-68d3-4181-8457-e5f00b5dd293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I don't like this. I think we should clean up our info.\n",
    "# We have two unique PAX named Gump\n",
    "# Amtrak has one account disabled\n",
    "# Delete all pending Slack invitations 2024-01-13\n",
    "\n",
    "df_users.drop_duplicates(subset=[\"email\"], keep=\"first\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7f584d-90af-444f-9f1a-9382753ae543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = df_users.groupby(\"user_name\")[\"email\"].agg(len)\n",
    "\n",
    "# df_users.loc[df_users.user_name.isin(x[x>1].index.values)].sort_values(\"user_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeae2b7b-5d20-4591-9a97-6c7d802b6842",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "insert_values = df_users[[\"user_name\", \"email\", \"region_id\"]].rename({\"region_id\": \"home_region_id\"}, axis=1).to_dict(\"records\")\n",
    "update_cols = (\"user_name\", \"email\", \"home_region_id\")\n",
    "user_insert_sql = insert_statement(cu, insert_values, update_cols)\n",
    "\n",
    "# print(sqlparse.format(user_insert_sql.compile(engine, compile_kwargs={'literal_binds': True}).__str__(), keyword_case='upper', reindent=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1eb0ec7-0568-4b07-80b4-cac122ea256e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_dup.loc[df_users_dup.user_id.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb49d2e-414b-4020-ae3c-be929173118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = dict(\n",
    "    user_id=pd.StringDtype(), # executive decision to use String instead of Int\n",
    "    user_name=pd.StringDtype(),\n",
    "    email=pd.StringDtype(),\n",
    "    home_region_id=pd.StringDtype() # executive decision to use String instead of Int\n",
    ")\n",
    "df_users = pd.read_sql(select(cu), engine, dtype=dtypes)\n",
    "df_users_dup = df_users_dup.merge(df_users[[\"email\", \"user_id\"]], on=\"email\", how=\"left\")\n",
    "\n",
    "insert_values = df_users_dup[[\"slack_user_id\", \"user_name\", \"email\", \"region_id\", \"user_id\"]].to_dict(\"records\")\n",
    "\n",
    "for d in insert_values:\n",
    "    try:\n",
    "        d[\"user_id\"] = int(d[\"user_id\"])\n",
    "    except TypeError:\n",
    "        pass # These are NA values being allowed to pass through\n",
    "\n",
    "update_cols = (\"user_name\", \"email\", \"region_id\", \"user_id\")\n",
    "user_dup_insert_sql = insert_statement(cud, insert_values, update_cols)\n",
    "\n",
    "# print(sqlparse.format(user_dup_insert_sql.compile(engine, compile_kwargs={'literal_binds': True}).__str__(), keyword_case='upper', reindent=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645670b3-ba99-4b9c-bdf9-5d0eed82f86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_values = df_aos[[\"slack_channel_id\", \"ao_name\", \"region_id\"]].to_dict(\"records\")\n",
    "update_cols = (\"ao_name\",)\n",
    "aos_insert_sql = insert_statement(ca, insert_values, update_cols)\n",
    "\n",
    "# print(sqlparse.format(aos_insert_sql.compile(engine, compile_kwargs={'literal_binds': True}).__str__(), keyword_case='upper', reindent=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fc0f7f-ddcd-4faf-a1de-47a39bc09c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\"ao_id\": pd.StringDtype(), # executive decision to use String instead of Int\n",
    "          \"slack_channel_id\": pd.StringDtype(),\n",
    "          \"ao_name\": pd.StringDtype(),\n",
    "          \"region_id\": pd.StringDtype(), # int in the SQL table, but joins with others are strings.\n",
    "         }\n",
    "df_aos = pd.read_sql(select(ca), engine, dtype=dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7973d2d8-db36-4501-a277-3855f4bf6042",
   "metadata": {},
   "outputs": [],
   "source": [
    "### beatdowns ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8ac824-681a-4384-a34e-9160887fd485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_user_id(slack_user_id):\n",
    "    match isinstance(slack_user_id, type(pd.NA)):\n",
    "        case True:\n",
    "            return pd.NA\n",
    "        case _:    \n",
    "            if slack_user_id.startswith(\"U\"):\n",
    "                return slack_user_id\n",
    "            elif \"team\" in slack_user_id:\n",
    "                return slack_user_id.split(\"/team/\")[1].split(\"|\")[0]\n",
    "            else:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6081a5bc-5b7d-4ffa-b360-752beeeac4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_beatdowns[\"slack_q_user_id\"] = df_beatdowns[\"slack_q_user_id\"].apply(extract_user_id).astype(pd.StringDtype())\n",
    "df_beatdowns[\"slack_coq_user_id\"] = df_beatdowns[\"slack_coq_user_id\"].apply(extract_user_id).astype(pd.StringDtype())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f387b07-2e2b-4e1f-b506-d40c59f76eda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_beatdowns = (df_beatdowns\n",
    "                .merge(df_users_dup[[\"slack_user_id\", \"user_id\", \"region_id\"]], \n",
    "                       left_on=[\"slack_q_user_id\", \"region_id\"],\n",
    "                       right_on=[\"slack_user_id\", \"region_id\"], \n",
    "                       how=\"left\")\n",
    "                .rename({\"user_id\": \"q_user_id\"}, axis=1)\n",
    "               .merge(df_users_dup[[\"slack_user_id\", \"user_id\", \"region_id\"]],\n",
    "                       left_on=[\"slack_coq_user_id\", \"region_id\"],\n",
    "                       right_on=[\"slack_user_id\", \"region_id\"],\n",
    "                       how=\"left\",)\n",
    "                .rename({\"user_id\": \"coq_user_id\"}, axis=1)\n",
    " .merge(\n",
    "    df_aos[[\"slack_channel_id\", \"ao_id\", \"region_id\"]],\n",
    "    on=[\"slack_channel_id\", \"region_id\"],\n",
    "    how=\"left\",\n",
    ")\n",
    ")\n",
    "df_beatdowns[\"fng_count\"] = df_beatdowns[\"fng_count\"].fillna(0) # no need to cast as int. Maybe still need fillna. unsure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd091c17-10e0-4b58-baba-4b0d3db8a99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ast.literal_eval(\n",
    "# for _, d in enumerate(insert_values):\n",
    "#     if d[\"json\"] is not None:\n",
    "#         print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ace80f2-b1a2-4bf5-a427-cc2d6a623aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_values = df_beatdowns[df_beatdowns[\"ao_id\"].notna()][\n",
    "    [\n",
    "        \"ao_id\",\n",
    "        \"bd_date\",\n",
    "        \"q_user_id\",\n",
    "        \"coq_user_id\",\n",
    "        \"pax_count\",\n",
    "        \"fng_count\",\n",
    "        \"timestamp\",\n",
    "        \"ts_edited\",\n",
    "        \"backblast\",\n",
    "        \"json\",\n",
    "    ]\n",
    "].to_dict(\"records\")\n",
    "#.replace(np.nan, None).to_dict(\"records\")\n",
    "# insert_values\n",
    "\n",
    "# below columns are INT in their target table. coerce them so they'll load properly\n",
    "for d in insert_values:\n",
    "    for col in (\"ao_id\", \"q_user_id\", \"coq_user_id\"):\n",
    "        try:\n",
    "            d[col] = int(d[col])\n",
    "        except TypeError:\n",
    "            pass\n",
    "    if d[\"json\"] is not None:\n",
    "        d[\"json\"] = ast.literal_eval(d[\"json\"]) # on the fence. This may not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751e1464-e3a8-4d7a-b8f3-7c1d752da634",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_cols = (\"coq_user_id\", \"pax_count\", \"fng_count\", \"timestamp\", \"ts_edited\", \"backblast\", \"json\")\n",
    "\n",
    "beatdowns_insert_sql = insert_statement(cb, insert_values, update_cols)\n",
    "# print(\n",
    "#     sqlparse.format(\n",
    "#         beatdowns_insert_sql.compile(engine, compile_kwargs={'literal_binds': True})\n",
    "#         .__str__(), keyword_case='upper', reindent=True)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b984a78-7531-43bb-8f62-93484e519c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = dict(beatdown_id=pd.StringDtype(),\n",
    "              ao_id=pd.StringDtype(),\n",
    "              q_user_id=pd.StringDtype(),\n",
    "              coq_user_id=pd.StringDtype(),\n",
    "              pax_count=pd.Int16Dtype(),\n",
    "              fng_count=pd.Int16Dtype(),\n",
    "              timestamp=pd.Float64Dtype(),\n",
    "              ts_edited=pd.Float64Dtype(),\n",
    "              backblast=pd.StringDtype(),\n",
    "              json=pd.StringDtype(),\n",
    "             )\n",
    "df_beatdowns = pd.read_sql(select(cb), engine, parse_dates=\"bd_date\", dtype=dtypes)\n",
    "df_beatdowns.q_user_id = df_beatdowns.q_user_id.astype(pd.Float64Dtype()).astype(pd.Int64Dtype()).astype(pd.StringDtype())\n",
    "# need to cast q_user_id as above. In the data it's integer.\n",
    "# pandas reads it as a float with \".0\" at the end. This trims that so the subsequent pandas joins work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b4dcb5-2894-4b34-b85a-76af7534d6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Attendance ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5409270-cb7e-4d53-b688-cfe66399e7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attendance[\"slack_user_id\"] = df_attendance[\"slack_user_id\"].apply(extract_user_id).astype(pd.StringDtype())\n",
    "df_attendance[\"slack_q_user_id\"] = df_attendance[\"slack_q_user_id\"].apply(extract_user_id).astype(pd.StringDtype())\n",
    "df_attendance = (df_attendance.merge(\n",
    "    df_users_dup[[\"slack_user_id\", \"user_id\", \"region_id\"]],\n",
    "    left_on=[\"slack_q_user_id\", \"region_id\"],\n",
    "    right_on=[\"slack_user_id\", \"region_id\"],\n",
    "    how=\"left\",\n",
    ").rename({\"user_id\": \"q_user_id\", \"slack_user_id_x\": \"slack_user_id\"}, axis=1)\n",
    " .drop(\"slack_user_id_y\", axis=1)\n",
    ").merge(\n",
    "    df_users_dup[[\"slack_user_id\", \"user_id\", \"region_id\"]],\n",
    "    on=[\"slack_user_id\", \"region_id\"],\n",
    "    how=\"left\",\n",
    ").merge(\n",
    "    df_aos[[\"slack_channel_id\", \"ao_id\", \"region_id\"]],\n",
    "    on=[\"slack_channel_id\", \"region_id\"],\n",
    "    how=\"left\",\n",
    ").merge(\n",
    "    df_beatdowns[[\"beatdown_id\", \"bd_date\", \"q_user_id\", \"ao_id\"]],\n",
    "    on=[\"bd_date\", \"q_user_id\", \"ao_id\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "df_attendance.drop_duplicates(subset=[\"beatdown_id\", \"user_id\"], inplace=True)\n",
    "df_attendance = df_attendance[df_attendance[\"beatdown_id\"].notnull()]\n",
    "df_attendance = df_attendance[df_attendance[\"user_id\"].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750c56ad-e55c-41a1-9603-495cc119f125",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_values = df_attendance[[\"beatdown_id\", \"user_id\", \"json\"]].to_dict(\"records\")\n",
    "update_cols = (\"beatdown_id\", \"json\")\n",
    "attendance_insert_sql = insert_statement(catt, insert_values, update_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483ed714-38c0-475b-baa7-e8c3279eb7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### region ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9679cbfe-635d-41cc-b7ab-ea24cf69393a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as cnxn:\n",
    "    df_regions = pd.read_sql(paxminer_region_sql, cnxn)\n",
    "    insert_values = df_regions[[\"schema_name\", \"region_name\", \"max_timestamp\", \"max_ts_edited\"]].to_dict(\"records\")\n",
    "    update_cols = (\"region_name\", \"max_timestamp\", \"max_ts_edited\")\n",
    "    region_insert_sql = insert_statement(cr, insert_values, update_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f2ee1b-33e9-4144-8997-c3f54490abbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
